{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2a (CS824)\n",
    "\n",
    "##### This lab and the next (Lab 2b) are based on some excellent material that was developed in 2017 by Barba and Clementi. There seemed little point in reproducing something that they had already clearly laid out with explanations. I have added a few points where I wanted to emphasise certain things or get you to apply some Python skills.\n",
    "\n",
    "### There are a few sections marked \"Exercise\" where you need to stop, think and do a little coding. But only the material from Lab 2c needs to be submitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Content under Creative Commons Attribution license CC-BY 4.0, code under BSD 3-Clause License © 2017 L.A. Barba, N.C. Clementi\n",
    "\n",
    "Based on [Module 2 - Lesson 1 from the Barba/Clementi material on Engineering Computation](https://github.com/engineersCode/EngComp2_takeoff) to which I {CWR} have made a few edits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheers!  Stats with Beers\n",
    "\n",
    "\n",
    "\n",
    "This module explores practical statistical analysis with Python; this first lesson explores how we can answer questions using data combined with practical methods from statistics.\n",
    "\n",
    "We'll need some fun data to work with. We found a neat data set of canned craft beers in the US, scraped from the web and cleaned up by Jean-Nicholas Hould ([@NicholasHould](https://twitter.com/NicholasHould?lang=en) on Twitter)—who we want to thank for having a permissive license on his GitHub repository so we can reuse his [work](https://github.com/nickhould/craft-beers-dataset)!\n",
    "\n",
    "The data source ([@craftcans](https://twitter.com/craftcans) on Twitter) doesn't say that the set includes *all* the canned beers brewed in the country. So we have to asume that the data is a sample and may contain biases.\n",
    "\n",
    "We'll manipulate the data using **NumPy**—the array library for Python that we learned about in [Module 1, lesson 4](http://go.gwu.edu/engcomp1lesson4). But we'll also learn about a new Python library for data analysis called **pandas**. \n",
    "\n",
    "[`pandas`](http://pandas.pydata.org/) is an open-source library providing high-performance, easy-to-use data structures and data-analysis tools.  Even though `pandas` is great for data analysis, we won't exploit all its power in this lesson. But we'll learn more about it later on!\n",
    "\n",
    "We'll use `pandas` to read the data file (in `csv` format, for comma-separated values), display it in a nice table, and extract the columns that we need—which we'll convert to `numpy` arrays to work with.\n",
    "\n",
    "Let's start by importing the two Python libraries that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read the data file\n",
    "\n",
    "Below, we'll take a peek into the data file, `beers.csv,` using the system command `head` (which we can use with a bang, thanks to IPython).\n",
    "\n",
    "But first, we will download the data using a Python library for opening a URL on the Internet. We created a short URL for the data file in the public repository with our course materials.\n",
    "\n",
    "The cell below should download the data in your current working directory. The next cell shows you the first few lines of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('beers.csv', <http.client.HTTPMessage at 0x7f7a978e8070>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "URL = 'http://go.gwu.edu/engcomp2data1'\n",
    "urlretrieve(URL, 'beers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",abv,ibu,id,name,style,brewery_id,ounces\r\n",
      "0,0.05,,1436,Pub Beer,American Pale Lager,408,12.0\r\n",
      "1,0.066,,2265,Devil's Cup,American Pale Ale (APA),177,12.0\r\n",
      "2,0.071,,2264,Rise of the Phoenix,American IPA,177,12.0\r\n",
      "3,0.09,,2263,Sinister,American Double / Imperial IPA,177,12.0\r\n",
      "4,0.075,,2262,Sex and Candy,American IPA,177,12.0\r\n",
      "5,0.077,,2261,Black Exodus,Oatmeal Stout,177,12.0\r\n",
      "6,0.045,,2260,Lake Street Express,American Pale Ale (APA),177,12.0\r\n",
      "7,0.065,,2259,Foreman,American Porter,177,12.0\r\n",
      "8,0.055,,2258,Jade,American Pale Ale (APA),177,12.0\r\n"
     ]
    }
   ],
   "source": [
    "!head \"beers.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{CWR} This illustrates the issue of using command line statements within Jupyter...  i.e. This will work fine if you are in a Linux environment but will throw an error in Windows as there is no built-in 'head' operator in Windows. (Of course once we load the data into a Pandas data-frame then we can use the 'Head' method from Pandas.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pandas` to read the data from the `csv` file, and save it into a new variable called `beers`. Let's then check the type of this new variable — we can use the function `type()` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers = pd.read_csv(\"beers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable      Type         Data/Info\n",
      "------------------------------------\n",
      "URL           str          http://go.gwu.edu/engcomp2data1\n",
      "beers         DataFrame          Unnamed: 0    abv  <...>\\n[2410 rows x 8 columns]\n",
      "np            module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "numpy         module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "pandas        module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pd            module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "urlretrieve   function     <function urlretrieve at 0x7f7ad440aee0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(beers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a new data type for us: a `pandas DataFrame`. From the `pandas` documentation: \"A `DataFrame`  is a 2-dimensional labeled data structure with columns of potentially different types\" [4]. You can think of it as the contents of a spreadsheet, saved into one handy Python variable. If you print it out, you get a nicely laid-out table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1436</td>\n",
       "      <td>Pub Beer</td>\n",
       "      <td>American Pale Lager</td>\n",
       "      <td>408</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2265</td>\n",
       "      <td>Devil's Cup</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2264</td>\n",
       "      <td>Rise of the Phoenix</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2263</td>\n",
       "      <td>Sinister</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2262</td>\n",
       "      <td>Sex and Candy</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>2405</td>\n",
       "      <td>0.067</td>\n",
       "      <td>45.0</td>\n",
       "      <td>928</td>\n",
       "      <td>Belgorado</td>\n",
       "      <td>Belgian IPA</td>\n",
       "      <td>424</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>0.052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>807</td>\n",
       "      <td>Rail Yard Ale</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>424</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>2407</td>\n",
       "      <td>0.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620</td>\n",
       "      <td>B3K Black Lager</td>\n",
       "      <td>Schwarzbier</td>\n",
       "      <td>424</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>2408</td>\n",
       "      <td>0.055</td>\n",
       "      <td>40.0</td>\n",
       "      <td>145</td>\n",
       "      <td>Silverback Pale Ale</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>424</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2409</td>\n",
       "      <td>0.052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>Rail Yard Ale (2009)</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>424</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2410 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    abv   ibu    id                  name  \\\n",
       "0              0  0.050   NaN  1436              Pub Beer   \n",
       "1              1  0.066   NaN  2265           Devil's Cup   \n",
       "2              2  0.071   NaN  2264   Rise of the Phoenix   \n",
       "3              3  0.090   NaN  2263              Sinister   \n",
       "4              4  0.075   NaN  2262         Sex and Candy   \n",
       "...          ...    ...   ...   ...                   ...   \n",
       "2405        2405  0.067  45.0   928             Belgorado   \n",
       "2406        2406  0.052   NaN   807         Rail Yard Ale   \n",
       "2407        2407  0.055   NaN   620       B3K Black Lager   \n",
       "2408        2408  0.055  40.0   145   Silverback Pale Ale   \n",
       "2409        2409  0.052   NaN    84  Rail Yard Ale (2009)   \n",
       "\n",
       "                               style  brewery_id  ounces  \n",
       "0                American Pale Lager         408    12.0  \n",
       "1            American Pale Ale (APA)         177    12.0  \n",
       "2                       American IPA         177    12.0  \n",
       "3     American Double / Imperial IPA         177    12.0  \n",
       "4                       American IPA         177    12.0  \n",
       "...                              ...         ...     ...  \n",
       "2405                     Belgian IPA         424    12.0  \n",
       "2406        American Amber / Red Ale         424    12.0  \n",
       "2407                     Schwarzbier         424    12.0  \n",
       "2408         American Pale Ale (APA)         424    12.0  \n",
       "2409        American Amber / Red Ale         424    12.0  \n",
       "\n",
       "[2410 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the table above we can see some aspects of the data. The first column is a numbering scheme for the beers. The other columns contain the following data:\n",
    "\n",
    "- `abv`: Alcohol-by-volume of the beer.\n",
    "- `ibu`: International Bittering Units of the beer.\n",
    "- `id`: Unique identifier of the beer.\n",
    "- `name`: Name of the beer.\n",
    "- `style`: Style of the beer.\n",
    "- `brewery_id`: Unique identifier of the brewery.\n",
    "- `ounces`: Ounces of beer in the can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data\n",
    "\n",
    "In the field of statistics, [Exploratory Data Analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis) (EDA) has the goal of summarizing the main features of our data, and seeing what the data can tell us without formal modeling or hypothesis-testing. [2]\n",
    "\n",
    "Let's start by extracting the columns with the `abv` and `ibu` values, and converting them to NumPy arrays. One of the advantages of data frames in `pandas` is that we can access a column simply using its header, like this:\n",
    "\n",
    "```python\n",
    "data_frame['name_of_column']\n",
    "```\n",
    "\n",
    "The output of this action is a `pandas Series`. From the documentation: \"a `Series` is a 1-dimensional labeled array capable of holding any data type.\" [4]\n",
    "\n",
    "Check the type of a column extracted by header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(beers['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can index and slice a data series like you know how to do with strings, lists and arrays. Here, we display the first ten elements of the `abv` series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    0.047\n",
       "2001    0.047\n",
       "2002    0.047\n",
       "2003    0.062\n",
       "2004    0.057\n",
       "2005    0.052\n",
       "2006    0.050\n",
       "2007    0.050\n",
       "2008    0.035\n",
       "2009    0.049\n",
       "2010    0.057\n",
       "2011    0.054\n",
       "2012    0.050\n",
       "2013    0.054\n",
       "2014    0.047\n",
       "2015    0.047\n",
       "2016    0.051\n",
       "2017    0.050\n",
       "2018    0.050\n",
       "2019    0.045\n",
       "2020    0.045\n",
       "2021    0.051\n",
       "2022    0.050\n",
       "2023    0.072\n",
       "2024    0.050\n",
       "2025    0.041\n",
       "2026    0.041\n",
       "2027    0.032\n",
       "2028    0.053\n",
       "2029    0.053\n",
       "2030    0.047\n",
       "2031    0.083\n",
       "2032    0.052\n",
       "2033    0.054\n",
       "2034    0.054\n",
       "2035    0.058\n",
       "2036    0.083\n",
       "2037    0.099\n",
       "2038    0.090\n",
       "2039    0.053\n",
       "2040    0.064\n",
       "2041    0.063\n",
       "2042    0.064\n",
       "2043    0.064\n",
       "2044      NaN\n",
       "2045    0.090\n",
       "2046    0.065\n",
       "2047    0.075\n",
       "2048    0.056\n",
       "2049    0.099\n",
       "Name: abv, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers['abv'][2000:2050]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data in the table again: you'll notice that there are `NaN` (not-a-number) elements in both the `abv` and `ibu` columns. Those values mean that there was no data reported for that beer. A typical task when cleaning up data is to deal with these `NaN`s.\n",
    "\n",
    "Let's extract the two series corresponding to the `abv` and `ibu` columns, clean the data by removing all `NaN` values, and then access the values of each series and assign them to a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_series = beers['abv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abv_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable      Type         Data/Info\n",
      "------------------------------------\n",
      "URL           str          http://go.gwu.edu/engcomp2data1\n",
      "abv_series    Series       0       0.050\\n1       0.<...>gth: 2410, dtype: float64\n",
      "beers         DataFrame          Unnamed: 0    abv  <...>\\n[2410 rows x 8 columns]\n",
      "np            module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "numpy         module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "pandas        module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pd            module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "urlretrieve   function     <function urlretrieve at 0x7f7ad440aee0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of `pandas` is that it has the ability to handle missing data. The  data-frame method `dropna()` returns a new data frame with only the good values of the original: all the null values are thrown out. This is super useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_clean = abv_series.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the length of the cleaned-up `abv` data; you'll see that it's shorter than the original. The `NaN` entries have gone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abv_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004    0.057\n",
       "2005    0.052\n",
       "2006    0.050\n",
       "2007    0.050\n",
       "2008    0.035\n",
       "2009    0.049\n",
       "2010    0.057\n",
       "2011    0.054\n",
       "2012    0.050\n",
       "2013    0.054\n",
       "2014    0.047\n",
       "2015    0.047\n",
       "2016    0.051\n",
       "2017    0.050\n",
       "2018    0.050\n",
       "2019    0.045\n",
       "2020    0.045\n",
       "2021    0.051\n",
       "2022    0.050\n",
       "2023    0.072\n",
       "2024    0.050\n",
       "2025    0.041\n",
       "2026    0.041\n",
       "2027    0.032\n",
       "2028    0.053\n",
       "2029    0.053\n",
       "2030    0.047\n",
       "2031    0.083\n",
       "2032    0.052\n",
       "2033    0.054\n",
       "2034    0.054\n",
       "2035    0.058\n",
       "2036    0.083\n",
       "2037    0.099\n",
       "2038    0.090\n",
       "2039    0.053\n",
       "2040    0.064\n",
       "2041    0.063\n",
       "2042    0.064\n",
       "2043    0.064\n",
       "2045    0.090\n",
       "2046    0.065\n",
       "2047    0.075\n",
       "2048    0.056\n",
       "2049    0.099\n",
       "2050    0.063\n",
       "2052    0.054\n",
       "2053    0.071\n",
       "2054    0.054\n",
       "2055    0.099\n",
       "Name: abv, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abv_clean[1950:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a `pandas` _Series_ consists of a column of values, and their labels. You can extract the values via the [`series.values`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.values.html) attribute, which returns a `numpy.ndarray` (multidimensional array). In the case of the `abv_clean` series, you get a one-dimensional array. We save it into the variable name `abv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1436</td>\n",
       "      <td>Pub Beer</td>\n",
       "      <td>American Pale Lager</td>\n",
       "      <td>408</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2265</td>\n",
       "      <td>Devil's Cup</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2264</td>\n",
       "      <td>Rise of the Phoenix</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2263</td>\n",
       "      <td>Sinister</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2262</td>\n",
       "      <td>Sex and Candy</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2261</td>\n",
       "      <td>Black Exodus</td>\n",
       "      <td>Oatmeal Stout</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2260</td>\n",
       "      <td>Lake Street Express</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2259</td>\n",
       "      <td>Foreman</td>\n",
       "      <td>American Porter</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2258</td>\n",
       "      <td>Jade</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2131</td>\n",
       "      <td>Cone Crusher</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    abv  ibu    id                 name  \\\n",
       "0           0  0.050  NaN  1436             Pub Beer   \n",
       "1           1  0.066  NaN  2265          Devil's Cup   \n",
       "2           2  0.071  NaN  2264  Rise of the Phoenix   \n",
       "3           3  0.090  NaN  2263             Sinister   \n",
       "4           4  0.075  NaN  2262        Sex and Candy   \n",
       "5           5  0.077  NaN  2261         Black Exodus   \n",
       "6           6  0.045  NaN  2260  Lake Street Express   \n",
       "7           7  0.065  NaN  2259              Foreman   \n",
       "8           8  0.055  NaN  2258                 Jade   \n",
       "9           9  0.086  NaN  2131         Cone Crusher   \n",
       "\n",
       "                            style  brewery_id  ounces  \n",
       "0             American Pale Lager         408    12.0  \n",
       "1         American Pale Ale (APA)         177    12.0  \n",
       "2                    American IPA         177    12.0  \n",
       "3  American Double / Imperial IPA         177    12.0  \n",
       "4                    American IPA         177    12.0  \n",
       "5                   Oatmeal Stout         177    12.0  \n",
       "6         American Pale Ale (APA)         177    12.0  \n",
       "7                 American Porter         177    12.0  \n",
       "8         American Pale Ale (APA)         177    12.0  \n",
       "9  American Double / Imperial IPA         177    12.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.050\n",
       "1    0.066\n",
       "2    0.071\n",
       "3    0.090\n",
       "4    0.075\n",
       "5    0.077\n",
       "6    0.045\n",
       "7    0.065\n",
       "8    0.055\n",
       "9    0.086\n",
       "Name: abv, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abv_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv = abv_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05  0.066 0.071 ... 0.055 0.055 0.052]\n"
     ]
    }
   ],
   "source": [
    "print(abv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(abv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable      Type         Data/Info\n",
      "------------------------------------\n",
      "URL           str          http://go.gwu.edu/engcomp2data1\n",
      "abv           ndarray      2348: 2348 elems, type `float64`, 18784 bytes\n",
      "abv_clean     Series       0       0.050\\n1       0.<...>gth: 2348, dtype: float64\n",
      "abv_series    Series       0       0.050\\n1       0.<...>gth: 2410, dtype: float64\n",
      "beers         DataFrame          Unnamed: 0    abv  <...>\\n[2410 rows x 8 columns]\n",
      "np            module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "numpy         module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "pandas        module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pd            module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "urlretrieve   function     <function urlretrieve at 0x7f7ad440aee0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the whole process for the `ibu` column: extract the column into a series, clean it up removing `NaN`s, extract the series values as an array, check how many values we lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibu_series = beers['ibu']\n",
    "\n",
    "total_len = len(ibu_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Cleaning\n",
    "ibu_clean = ibu_series.dropna()\n",
    "\n",
    "ibu = ibu_clean.values\n",
    "\n",
    "after_clean = len(ibu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.70124481327801"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution to exercise 2a.1\n",
    "(total_len - after_clean) / total_len *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.572614107883817"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_len_abv = len(beers['abv'])\n",
    "len_after_cleaning_abv = len(abv)\n",
    "\n",
    "(total_len_abv - len_after_cleaning_abv) / total_len_abv *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2a.1\n",
    "\n",
    "Write a Python statement that calculates the percentage of missing values for a certain data series. Use the function to calculate the percentage of missing values for the `abv` and `ibu` data sets. \n",
    "\n",
    "For the original series, before cleaning, remember that you can access the values with `series.values` (e.g., `abv_series.values`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outputs:\n",
    "\n",
    "You should see that in the case of the variable `ibu` we are missing almost 42% of the values. This is important, because it will affect our analysis. When we do descriptive statistics, we will ignore these missing values, and having 42% missing will very likely cause bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Ready, stats, go!\n",
    "\n",
    "\n",
    "Now that we have NumPy arrays with clean data, let's see how we can manipulate them to get some useful information. \n",
    "\n",
    "Focusing on the numerical variables `abv` and `ibu`, we'll walk through some \"descriptive statistics,\" below. In other words, we aim to generate statistics that summarize the data concisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum and minimum \n",
    "\n",
    "The maximum and minimum values of a dataset are helpful as they tell us the _range_ of our sample: the range gives some indication of the _variability_ in the data.\n",
    "We can obtain them for our `abv` and `ibu` arrays with the `min()` and `max()` functions from NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**abv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_min = numpy.min(abv)\n",
    "abv_max = numpy.max(abv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value for abv is:  0.001\n",
      "The maximum value for abv is:  0.128\n"
     ]
    }
   ],
   "source": [
    "print('The minimum value for abv is: ', abv_min)\n",
    "print('The maximum value for abv is: ', abv_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ibu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibu_min = numpy.min(ibu)\n",
    "ibu_max = numpy.max(ibu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value for ibu is:  4.0\n",
      "The maximum value for ibu is:  138.0\n"
     ]
    }
   ],
   "source": [
    "print('The minimum value for ibu is: ', ibu_min)\n",
    "print('The maximum value for ibu is: ', ibu_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean value\n",
    "\n",
    "The **mean** value is one of the main measures to describe the central tendency of the data: an indication of where's the \"center\" of the data. If we have a sample of $N$ values, $x_i$, the mean, $\\bar{x}$, is calculated by:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\bar{x} = \\frac{1}{N}\\sum_{i} x_i\n",
    "\\end{equation*}\n",
    "\n",
    "In words, that is the sum of the data values divided by the number of values, $N$. \n",
    "\n",
    "You've already learned how to write a function to compute the mean in [Module 1 Lesson 5](http://go.gwu.edu/engcomp1lesson5), but you also learned that NumPy has a built-in `mean()` function. We'll use this to get the mean of the `abv` and `ibu` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_mean = numpy.mean(abv)\n",
    "ibu_mean = numpy.mean(ibu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll print these two variables, but we'll use some fancy new way of printing with Python's string formatter, `string.format()`. There's a sweet site dedicated to Python's string formatter, called [PyFormat](https://pyformat.info), where you can learn lots of tricks!\n",
    "\n",
    "The basic trick is to use curly brackets `{}` as placeholder for a variable value that you want to print in the middle of a string (say, a sentence that explains what you are printing), and to pass the variable name as argument to `.format()`, preceded by the string.\n",
    "\n",
    "Let's try something out…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value for abv is 0.059773424190800666 and for ibu 42.71316725978647\n"
     ]
    }
   ],
   "source": [
    "print('The mean value for abv is {} and for ibu {}'.format(abv_mean, ibu_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh! That doesn't look very good, does it? Here's where Python's string formatting gets fancy. We can print fewer decimal digits, so the sentence is more readable. For example, if we want to have four decimal digits, we specify it this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value for abv is 0.06 and for ibu 42.71\n"
     ]
    }
   ],
   "source": [
    "print('The mean value for abv is {:.2f} and for ibu {:.2f}'.format(abv_mean, ibu_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the curly brackets—the placeholders for the values we want to print—the `f` is for `float` and the `.4` is for four digits after the decimal dot. The colon here marks the beginning of the format specification (as there are options that can be passed before). There are so many tricks to Python's string formatter that you'll usually look up just what you need.\n",
    "Another useful resource for string formatting is the [Python String Format Cookbook](https://mkaz.blog/code/python-string-format-cookbook/). Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median value for abv is 0.06 and for ibu 35.00\n"
     ]
    }
   ],
   "source": [
    "abv_median = numpy.median(abv)\n",
    "ibu_median = numpy.median(ibu)\n",
    "print('The median value for abv is {:.2f} and for ibu {:.2f}'.format(abv_median, ibu_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeResult(mode=array([0.05]), count=array([215]))\n",
      "ModeResult(mode=array([20.]), count=array([82]))\n",
      "The modal value for abv is ModeResult(mode=array([0.05]), count=array([215])) and for ibu ModeResult(mode=array([20.]), count=array([82]))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "abv_mode = stats.mode(abv)\n",
    "ibu_mode = stats.mode(ibu)\n",
    "print(abv_mode)\n",
    "print(ibu_mode)\n",
    "print('The modal value for abv is {} and for ibu {}'.format(abv_mode, ibu_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The modal value for abv is ModeResult(mode=array([0.05]), count=array([215])) and for ibu ModeResult(mode=array([20.]), count=array([82]))\n"
     ]
    }
   ],
   "source": [
    "# The example above demonstrates where you need to check the format of a values returned from a function - in this\n",
    "# case 'mode' which returns more than just the modal value...\n",
    "\n",
    "abv_mode = stats.mode(abv)\n",
    "ibu_mode = stats.mode(ibu)\n",
    "print('The modal value for abv is {} and for ibu {}'.format(abv_mode, ibu_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and standard deviation\n",
    "\n",
    "While the mean indicates where's the center of your data, the **variance** and **standard deviation** describe the *spread* or variability of the data. We already mentioned that the _range_ (difference between largest and smallest data values) is also an indication of variability. But the standard deviation is the most common measure of variability.\n",
    "\n",
    "We really like the way [Prof. Kristin Sainani](https://profiles.stanford.edu/kristin-sainani), of Stanford University, presents this in her online course on [Statistics in Medicine](https://lagunita.stanford.edu/courses/Medicine/MedStats-SP/SelfPaced/about). In her lecture \"Describing Quantitative Data: Whhat is the variability in the data?\", available [on YouTube](https://youtu.be/hlFeEQF5tDc), she asks: _What if someone were to ask you to devise a statistic that gives the avarage distance from the mean?_ Think about this a little bit.\n",
    "\n",
    "The distance from the mean, for any data value, is $x_i - \\bar{x}$. So what is the average of the distances from the mean? If we try to simply compute the average of all the values $x_i - \\bar{x}$, some of which are negative, you'll just get zero! It doesn't work.\n",
    "\n",
    "Since the problem is the negative distances from the mean, you might suggest using absolute values. But this is just mathematically inconvenient. Another way to get rid of negative values is to take the squares. And that's how we get to the expression for the _variance_: it is the average of the squares of the deviations from the mean. For a set of $N$ values,\n",
    "\n",
    "\\begin{equation*}\n",
    "     \\text{var} = \\frac{1}{N}\\sum_{i} (x_i - \\bar{x})^2\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The variance itself is hard to interpret. The problem with it is that the units are strange (they are the square of the original units). The **standard deviation**, the square root of the variance, is more meaningful because it has the same units as the original variable. Often, the symbol $\\sigma$ is used for it:\n",
    "\n",
    "\\begin{equation*} \n",
    "    \\sigma = \\sqrt{\\text{var}} = \\sqrt{\\frac{1}{N}\\sum_{i} (x_i - \\bar{x})^2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample vs. population\n",
    "\n",
    "The above definitions are used when $N$ (the number of values) represents the entire population. But if we have a _sample_ of that population, the formulas have to be adjusted: instead of dividing by $N$ we divide by $N-1$. This is important, especially when we work with real data since usually we have samples of populations. \n",
    "\n",
    "The **standard deviation** of a sample is denoted by $s$, and the formula is:\n",
    "\n",
    "\\begin{equation*}     \n",
    "     s = \\sqrt{\\frac{1}{N-1}\\sum_{i} (x_i - \\bar{x})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Why? This gets a little technical, but the reason is that if you have a _sample_ of the population, you don't know the _real_ value of the mean, and $\\bar{x}$ is actually an _estimate_ of the mean. That's why you'll often find the symbol $\\mu$ used to denote the population mean, and distinguish it with the sample mean, $\\bar{x}$. Using $\\bar{x}$ to compute the standard deviation introduces a small bias: $\\bar{x}$ is computed _from the sample values_, and the data are on average (slightly) closer to $\\bar{x}$ than the population is to $\\mu$. Dividing by $N-1$ instead of $N$ corrects this bias!\n",
    "\n",
    "Prof. Sainani explains it by saying that we lost one degree of freedom when we estimated the mean using $\\bar{x}$.  For example, say we have 100 people and I give you their mean age, and the actual age for 99 people from the sample: you'll be able to calculate the age of that 100th person. Once we calculated the mean, we only have 99 degrees of freedom left because that 100th person's age is fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's code!\n",
    "\n",
    "Now that we have the math sorted out, we can program functions to compute the variance and the standard deviation. In our case, we are working with samples of the population of craft beers, so we need to use the formulas with $N-1$ in the denominator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_var(array):\n",
    "    \"\"\" Calculates the variance of an array that contains values of a sample of a \n",
    "    population. \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    array : array, contains sample of values. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    var   : float, variance of the array .\n",
    "    \"\"\"\n",
    "    \n",
    "    sum_sqr = 0 \n",
    "    mean = numpy.mean(array)\n",
    "    \n",
    "    for element in array:\n",
    "        sum_sqr += (element - mean)**2\n",
    "    \n",
    "    N = len(array)\n",
    "    var = sum_sqr / (N - 1)\n",
    "    \n",
    "    return var\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used `numpy.mean()` in our function: do you think we can make this function even more Pythonic? \n",
    "\n",
    "*Hint:* Yes!, we totally can.\n",
    "\n",
    "### Exercise  2a.2\n",
    "\n",
    "Re-write the function `sample_var()` using `numpy.sum()` to replace the `for`-loop. Name the function `var_pythonic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the sample variance, so we take its square root to get the standard deviation. We can make it a function, even though it's just one line of Python, to make our code more readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_std(array):\n",
    "    \"\"\" Computes the standard deviation of an array that contains values\n",
    "    of a sample of a population.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    array : array, contains sample of values. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    std   : float, standard deviation of the array.\n",
    "    \"\"\"\n",
    "    \n",
    "    std = numpy.sqrt(sample_var(array))\n",
    "    \n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call our brand new functions and assign the output values to new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_std = sample_std(abv)\n",
    "ibu_std = sample_std(ibu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print these values using the string formatter, only printing 4 decimal digits, we can display our descriptive statistics in a pleasant, human-readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The standard deviation for abv is {:.4f} and for ibu {:.4f}'.format(abv_std, ibu_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers tell us that the `abv` values are quite concentrated around the mean value, while the `ibu` values are quite spread out from their mean. How could we check these descriptions of the data? A good way of doing so is using graphics: various types of plots can tell us things about the data. \n",
    "\n",
    "We'll learn about _histograms_ in this lesson, and in the following lesson we'll explore _box plots_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "import math\n",
    "\n",
    "abv_var = numpy.var(abv)\n",
    "ibu_var = numpy.var(ibu)\n",
    "\n",
    "abv_sd1 = math.sqrt(abv_var)\n",
    "ibu_sd1 = math.sqrt(ibu_var)\n",
    "\n",
    "abv_sd2 = stats.stdev(abv)\n",
    "ibu_sd2 = stats.stdev(ibu)\n",
    "\n",
    "print('The variance for abv is {:.4f} and for ibu {:.4f}'.format(abv_var, ibu_var))\n",
    "print('The standard deviation for abv is {:.4f} and for ibu {:.4f}'.format(abv_sd2, ibu_sd2))\n",
    "\n",
    "print('A rough estm of standard deviation for abv is {:.4f} and for ibu {:.4f}'.format(abv_sd1, ibu_sd1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Distribution plots \n",
    "\n",
    "Every time that we work with data, visualizing it is very useful. Visualizations give us a better idea of how our data behaves. One way of visualizing data is with a frequency-distribution plot known as **histogram**: a graphical representation of how the data is distributed. To make a histogram, first we need to \"bin\" the range of values (divide the range into intervals) and then we count how many data values fall into each interval. The intervals are usually consecutive (not always), of equal size and non-overlapping. \n",
    "\n",
    "Thanks to Python and Matplotlib, making histograms is easy. We recommend that you always read the documentation, in this case about [histograms](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.hist.html). We'll show you here an example using the `hist()` function from `pyplot`, but this is just a starting point. \n",
    "\n",
    "Let's import the libraries that we need for plotting, as you learned in [Module 1 Lesson 5](http://go.gwu.edu/engcomp1lesson5), then study the plotting commands used below. Try changing some of the plot options and seeing the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "#Import rcParams to set font styles\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#Set font style and size \n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can set the size of the figure by doing:\n",
    "pyplot.figure(figsize=(10,5))\n",
    "\n",
    "#Plotting\n",
    "pyplot.hist(abv, bins=20, color='#3498db', histtype='bar', edgecolor='white') \n",
    "#The \\n is to leave a blank line between the title and the plot\n",
    "pyplot.title('abv \\n')\n",
    "pyplot.xlabel('Alcohol by Volume (abv) ')\n",
    "pyplot.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't specify this then the next plot will be a smaller (default) size\n",
    "# which can make comparing figures a bit more tricky\n",
    "# pyplot.figure(figsize=(10,5))\n",
    "\n",
    "#Plotting\n",
    "pyplot.hist(ibu, bins=20, color='#e67e22', histtype='bar', edgecolor='white') \n",
    "#The \\n is to leave a blanck line between the title and the plot\n",
    "pyplot.title('ibu \\n')\n",
    "pyplot.xlabel('International Bittering Units (ibu)')\n",
    "pyplot.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  2a.3\n",
    "\n",
    "Play around with the plots, change the values of the bins, colors, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with a normal distribution\n",
    "\n",
    "A **normal** (or Gaussian) distribution is a special type of distrubution that behaves as shown in the figure: 68% of the values are within one standard deviation $\\sigma$ from the mean; 95% lie within $2\\sigma$; and at a distance of $\\pm3\\sigma$ from the mean, we cover 99.7% of the values. This fact is known as the $3$-$\\sigma$ rule, or 68-95-99.7 (empirical) rule.\n",
    "\n",
    "<img src=\"../images/std_bell_curve.png\" style=\"width: 800px;\"/> \n",
    "####  Standard deviation and coverage in a normal distribution. Modified figure based on original from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Standard_deviation_diagram.svg), the free media repository.\n",
    "\n",
    "\n",
    "Notice that our histograms don't follow the shape of a normal distribution, known as *Bell Curve*. Our histograms are not centered in the mean value, and they are not symetric with respect to it. They are what we call **skewed** to the right (yes, to the _right_). A right (or positive) skewed distribution  looks like it's been pushed to the left: the right tail is longer and most of the values are concentrated on the left of the figure. Imagine that \"right-skewed\" means that a force from the right pushes on the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss in your group\n",
    "\n",
    "* How do you think that skewness will affect the percentages of coverage by standard deviation compared to the Bell Curve?\n",
    "\n",
    "* Can we calculate those percentages? \n",
    "\n",
    "### Exercise  2a.4\n",
    "\n",
    "Yes we can, and guess what: we can do it in a few lines of Python. But before doing that, we want you to explain in your own words how the following piece of code works. \n",
    "\n",
    "*Hints:* \n",
    "\n",
    "1. Check what the logical operation `numpy.logical_and(1<x, x<4)` returns.\n",
    "2. Check what happens if you sum booleans. For example, `True + True`, `True + False` and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.array([1,2,3,4])\n",
    "num_ele = numpy.logical_and(1<x, x<4).sum()\n",
    "print(num_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the same idea, we will calculate the number of elements in each interval of width $(1\\sigma, 2\\sigma, 3\\sigma)$, and get the corresponding percentage. \n",
    "\n",
    "### Exercise  2a.5\n",
    "\n",
    "Since we want to compute this for both of our variables, `abv` and `ibu`, we'll write a function to do so. Discuss the code below in your group - make sure that you understand how it is operating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_percentages(x, x_mean, x_std):\n",
    "    \"\"\" Computes the percentage of coverage at 1std, 2std and 3std from the\n",
    "    mean value of a certain variable x.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x      : array, data we want to compute on. \n",
    "    x_mean : float, mean value of x array.\n",
    "    x_std  : float, standard deviation of x array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    per_std_1 : float, percentage of values within 1 standard deviation.\n",
    "    per_std_2 : float, percentage of values within 2 standard deviations.\n",
    "    per_std_3 : float, percentage of values within 3 standard deviations.    \n",
    "    \"\"\"\n",
    "    \n",
    "    std_1 = x_std\n",
    "    std_2 = 2 * x_std\n",
    "    std_3 = 3 * x_std\n",
    "    \n",
    "    elem_std_1 = numpy.logical_and((x_mean - std_1) < x, x < (x_mean + std_1)).sum()\n",
    "    per_std_1 = elem_std_1 * 100 / len(x) \n",
    "    \n",
    "    elem_std_2 = numpy.logical_and((x_mean - std_2) < x, x < (x_mean + std_2)).sum()\n",
    "    per_std_2 = elem_std_2 * 100 / len(x) \n",
    "    \n",
    "    elem_std_3 = numpy.logical_and((x_mean - std_3) < x, x < (x_mean + std_3)).sum()\n",
    "    per_std_3 = elem_std_3 * 100 / len(x) \n",
    "    \n",
    "    return per_std_1, per_std_2, per_std_3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the percentages next. Notice that the function above returns three values. If we want to assign each value to a different variable, we need to follow a specific syntax. In our example this would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**abv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv_std1_per, abv_std2_per, abv_std3_per = std_percentages(abv, abv_mean, abv_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty-print the values of our variables so we can inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The percentage of coverage at 1 std of the abv_mean is : {:.2f} %'.format(abv_std1_per))\n",
    "print('The percentage of coverage at 2 std of the abv_mean is : {:.2f} %'.format(abv_std2_per))\n",
    "print('The percentage of coverage at 3 std of the abv_mean is : {:.2f} %'.format(abv_std3_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ibu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibu_std1_per, ibu_std2_per, ibu_std3_per = std_percentages(ibu, ibu_mean, ibu_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The percentage of coverage at 1 std of the ibu_mean is : {:.2f} %'.format(ibu_std1_per))\n",
    "print('The percentage of coverage at 2 std of the ibu_mean is : {:.2f} %'.format(ibu_std2_per))\n",
    "print('The percentage of coverage at 3 std of the ibu_mean is : {:.2f} %'.format(ibu_std3_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in both cases the percentages are not that far from the values for normal distribution (68%, 95%, 99.7%), especially for $2\\sigma$ and $3\\sigma$. So usually you can use these values as a rule of thumb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we've learned\n",
    "\n",
    "* Read data from a `csv` file using `pandas`.\n",
    "* The concepts of Data Frame and Series in `pandas`.\n",
    "* Clean null (NaN) values from a Series using `pandas`.\n",
    "* Convert a `panda`s Series into a `numpy` array.\n",
    "* Compute maximum and minimum, and range.\n",
    "* Revise concept of mean value.\n",
    "* Compute the variance and standard deviation.\n",
    "* Use the mean and standard deviation to understand how the data is distributed.\n",
    "* Plot frequency distribution diagrams (histograms).\n",
    "* Normal distribution and 3-sigma rule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Craft beer datatset](https://github.com/nickhould/craft-beers-dataset) by Jean-Nicholas Hould.\n",
    "2. [Exploratory Data Analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis), Wikipedia article.\n",
    "3. _Think Python: How to Think Like a Computer Scientist_ (2012). Allen Downey. Green Tea Press.  [PDF available](http://greenteapress.com/thinkpython/thinkpython.pdf)\n",
    "4. [Intro to data Structures](https://pandas.pydata.org/pandas-docs/stable/dsintro.html), `pandas` documentation.\n",
    "5. _Think Stats: Probability and Statistics for Programmers_ version 1.6.0 (2011). Allen Downey. Green Tea Press.  [PDF available](http://greenteapress.com/thinkstats/thinkstats.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
