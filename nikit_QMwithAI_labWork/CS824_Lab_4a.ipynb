{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> CS824 - Lab 4a (2022) </div>\n",
    "\n",
    "# Simple application of Bayes Law\n",
    "\n",
    "As usual, follow those parts of the lab that have been set up - sometimes involving aspects of Python that you may not yet be familiar with, but try to make sure you get a feel for what is happening in terms of **probability** and **Bayes**...  There are various 'exercises' which are the elements that should form part of this week's submission (\"SUBMIT\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 1: Using Bayes to understand medical diagnosis\n",
    "\n",
    "Depending on how familiar you are with the terms from medical diagnosis you may need to refer to the formulae in mini-lecture 4.2 to translate the example below into a function that uses Bayes Law to properly interpret the results from diagnostic tests.\n",
    "\n",
    "## Exercise 1a (SUBMIT)\n",
    "Build a function in Python that takes in the following three parameters:\n",
    "- the prevalence of some disease in a population (sometimes called the 'base rate')\n",
    "- the sensitivity of a diagnostic test (also referred to as the 'true positive rate')\n",
    "- the specificity of a diagnostic test (also referred to as the 'true negative rate')\n",
    "\n",
    "<br> and returns a value that represents the probability that a patient from that population has the disease based on getting a positive result from such a test.\n",
    "\n",
    "Start with the example from the mini-lecture, i.e.:\n",
    "- prevalence of some rare disease = 1 in 5,000\n",
    "- sensitivity = 99%\n",
    "- specificity = 95%\n",
    "\n",
    "<br>Given these parameters your function should return a value of around 0.4%, - i.e. the P(disease | +test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This function uses the Bayes Theorem, to calculate the probability\n",
    "if the patient has the disease.\n",
    "        P(D|T+) = (P(T+|D) * P(D))/P(T+)\n",
    "        where,\n",
    "        P(D|T+) is the probability of actually having the disease\n",
    "        P(T+|D) is the probability of testing positive and having the disease\n",
    "        P(D)    is the PRIOR probability of having the disease\n",
    "        P(T+)   is the probability of testing positive\n",
    "\n",
    "P(T+) can be calculated using the following formula\n",
    "        P(T+) = P(D) * P(T+|D) + P(D-) * P(T-|D)\n",
    "        where,\n",
    "        P(D-)   is the PRIOR probability of NOT having the disease\n",
    "        P(T-|D) is the probability of testing negative but having the disease \n",
    "Arguments\n",
    "---------\n",
    "base_rate  : float, prevalence of the disease\n",
    "true_P_rate: float, this is the true positive rate or sometimes called\n",
    "                    the sensitivity\n",
    "true_N_rate: float, this is the true negative rate or sometimes called\n",
    "                    the specificity\n",
    "\n",
    "Returns\n",
    "-------\n",
    "the probability that the specific patient has the disease\n",
    "'''\n",
    "def my_func(base_rate, true_P_rate, true_N_rate):\n",
    "    prob_of_disease =  0                     # probability of actually having the disease\n",
    "    prob_pos_W_dis  = true_P_rate            # probability of testing positive and having the disease\n",
    "    prob_pos_WO_dis = (1-true_N_rate)        # probability of testing negative but having the disease \n",
    "    prob_actual_dis = base_rate              # PRIOR probability of having the disease\n",
    "    prob_no_dis     = (1-prob_actual_dis)    # PRIOR probability of NOT having the disease\n",
    "    # probability of testing positive\n",
    "    prob_pos_test   = (prob_pos_W_dis*prob_actual_dis) \\\n",
    "                      + ((prob_pos_WO_dis)*(prob_no_dis))\n",
    "\n",
    "    \n",
    "    prob_of_disease = prob_actual_dis * (prob_pos_W_dis/prob_pos_test) * 100\n",
    "\n",
    "    return prob_of_disease\n",
    "\n",
    "\n",
    "prevalance  = 1/5000\n",
    "sensitivity = 0.99\n",
    "specificity = 0.95\n",
    "patient_having_disease =  my_func(prevalance, sensitivity, specificity)\n",
    "print('{0:.2f}'.format(patient_having_disease))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1b (SUBMIT)\n",
    "How (if at all) does your belief that this patient has the disease alter if she gets a **second** positive test? (Assume this has the same 'test characteristics' but is run by a different lab, just so that we know the two tests are in some way independent.) Does that makes sense to you?\n",
    "\n",
    "#### The result that I came up with increased the probability to just over 7%. This is now starting to get a bit more serious/worrying...  Did you get the same result? Do you trust this value?  If not, why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.27\n"
     ]
    }
   ],
   "source": [
    "# Here we change the base rate to the rate by the first test's probability.\n",
    "# Which is now the posterior probability of having the disease\n",
    "patient_second_positive = my_func(patient_having_disease/100, sensitivity, specificity)\n",
    "print('{0:.2f}'.format(patient_second_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c (SUBMIT)\n",
    "What about if the level of specificity is equal to that of the sensitivity - i.e. both are at 99%.  How does this alter things? (Look at this for both the first and subsequent runs of this 'new improved' test.) \n",
    "\n",
    "#### Did the new outcomes surprise you?  Again would you intuitively accept/'believe' these numbers? How have these exercises impacted on your understanding of how 'sensitivity' and 'specificity' in diagnositc tests should be understood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94\n"
     ]
    }
   ],
   "source": [
    "same_sense = sensitivity            # We assign the sensitivity, which will be used as specificity\n",
    "sen_equal_spec_first_run = my_func(prevalance, sensitivity, same_sense)\n",
    "print('{0:.2f}'.format(sen_equal_spec_first_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.17\n"
     ]
    }
   ],
   "source": [
    "# Here we use the 'sen_equal_spec_first_run' and use it as our posterior probability of having a disease\n",
    "# This is the case where the specificity is equal to the sensitivity \n",
    "sen_equal_spec_second_run = my_func(patient_having_disease/100, sensitivity, same_sense)\n",
    "print('{0:.2f}'.format(sen_equal_spec_second_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d (SUBMIT)\n",
    "Have a look at the situation for **COVID-19**:\n",
    "- you will need to check the Web for a suitable base rate to explore this issue, as well as commonly accepted test characteristics. If you find suggestions that specificity is 100% (as some do) then you may be more interested in the presence of COVID in an indivdual who has tested NEGATIVE (explain why the positive outome case is 'uninteresting' in this context). You may wish to look at both PCR and lateral flow tests (LFTs) when carrying out this exercise.\n",
    "\n",
    "<br> Which of the parameters seems to have the largest impact on the outcome (i.e. your belief that there really is something that you should be worried about and/or relaxed enough to ignore, given different outcomes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0420\n",
      "0.4191\n",
      "0.2098\n",
      "0.0200\n",
      "0.0999\n"
     ]
    }
   ],
   "source": [
    "def my_func_2(base_rate, true_P_rate, true_N_rate):\n",
    "    prob_of_disease =  0                    # probability of actually having the disease however tested negative\n",
    "    prob_neg_W_dis  = (1-true_P_rate)       # probability of testing negative but having the disease\n",
    "    prob_neg_WO_dis = true_N_rate           # probabiliry of testing negative and not having the disease\n",
    "    prob_actual_dis = base_rate             # PRIOR probability of  having the disease\n",
    "    prob_no_dis     = (1 - base_rate)       # probability of not having the disease\n",
    "    # Probability of testing negative\n",
    "    prob_neg_test   = (prob_neg_W_dis*prob_actual_dis) \\\n",
    "                      + ((prob_neg_WO_dis)*(prob_no_dis))\n",
    "\n",
    "    prob_of_disease = prob_actual_dis * (prob_neg_W_dis/prob_neg_test) * 100\n",
    "\n",
    "    return prob_of_disease\n",
    "\n",
    "'''\n",
    "The parameter which has a large imapct is the base rate, as it defines probability \n",
    "the one individual can have that disease.\n",
    "With increase in sample, the rate which showcases the disease probability\n",
    "\n",
    "The sensitivity wiht varying condition. shows less of an impact\n",
    "'''\n",
    "prevalance  = 1/5000\n",
    "sensitivity = 0.79\n",
    "specificity = 0.1\n",
    "patient_false_negative   =  my_func_2(prevalance, sensitivity, specificity)\n",
    "patient_false_negative_1 =  my_func_2(10/5000, sensitivity, specificity)\n",
    "patient_false_negative_2 =  my_func_2(10/10000, sensitivity, specificity)\n",
    "patient_false_negative_3 =  my_func_2(prevalance, 0.9, specificity)\n",
    "patient_false_negative_4 =  my_func_2(prevalance, 0.5, specificity)\n",
    "print('{0:.4f}'.format(patient_false_negative))\n",
    "print('{0:.4f}'.format(patient_false_negative_1))\n",
    "print('{0:.4f}'.format(patient_false_negative_2))\n",
    "print('{0:.4f}'.format(patient_false_negative_3))\n",
    "print('{0:.4f}'.format(patient_false_negative_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Part 2: M&Ms and Bayes\n",
    "\n",
    "So-called 'urn' (or 'bag') problems don't always present in the *classic* manner we came across last week - dating back to Bernoulli. The problem below is in the same basic format as the 'urn' problems of last week but allow for a little bit of a twist. This example is based on an example around the American candy, M&Ms and their production over time, and is based on an entry from [Allen Downey's](https://www.allendowney.com/blog/) excellent blog (though as always, any errors introduced in editing are entirely my fault!)\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the colour mix in a bag of M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  After 1995 it was (24% Blue, 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown).\n",
    "\n",
    "> A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996 but won't tell me which is which. He gives me a yellow M&M, what is the probability that this came from the 1994 bag?\n",
    "\n",
    "Now that you have picked up on the basic ideas of Bayesian reasoning you should see that this seems to be a good candidate, in that we are asked to estimate the probability of a hypothesis (that the yellow M&M is from 1994) given some evidence. It is not immediately obvivous how we might do this but we should be able to take the probabilities that we have been given and work in the 'opposite' direction, i.e. what is the probability that we would have recieved this 'evidence' under the different hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You may feel that all this reasoning is 'over-kill', but we are going to add a bit more evidence in a moment, so breaking down our thinking in this way will ultimately pay off...\n",
    "\n",
    "Before we see the colour of the M&M, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: the M&M was from the 94 bag\n",
    "    B: the M&M was from the 96 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "Then we get some evidence:\n",
    "    \n",
    "    E: the M&M is yellow\n",
    "    \n",
    "We want to know the probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "We *could* enumerate the sample space to estimate this but that will start to become more tricky as we are given more evidence (see below). So instead let's take what we know from Bayes' Theorem, namely that:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the right-hand-side of this equation are all pretty straight-forward to calculate:\n",
    "    \n",
    "    P(E | A) = 0.20\n",
    "    P(E | B) = 0.14\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.20     * 0.5  + 0.14     * 0.5   =   0.17\n",
    "    \n",
    "We can use Bayes Law to get a final answer:\n",
    "   \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.20     * 0.5  / 0.17 \n",
    "             = 0.588\n",
    "\n",
    "i.e. There is about a 59% chance that this yellow M&M was taken was the 1994 bag.  \n",
    "\n",
    "You may say, \"well that was a LOT of work to calcuate what was a lot more obvious, by simply noting that 20/34 (i.e. 1994_yellows / all_yellows) is the proportion / likelihood of the yellow coming from the 1994 bag\". And you would be correct, but see whether your mind might change when faced with the next question...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2a (SUBMIT)\n",
    "\n",
    "Let's think about a slightly more 'interesting' situation...  Say this time that our friend draws one M&M from each bag - the first one is yellow and the seceond one is green. Now how might you go about estimating the probability that the yellow M&M came from the 1994 bag?\n",
    "\n",
    "<br>\n",
    "You should be able to use the approach outlined above to estimate this value. It would be great to build a little 'Bayes estimator' function in Python to explore this and then other selections of M&Ms, so try to create that rather than (or in addition to) working our each option *by hand* (as we did above).\n",
    "\n",
    "<br>\n",
    "(I estimated that there was now a 74% chance that the yellow M&M came from the 1994 bag... Did you find the same?  Does this value make sense to you?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7407407407407408, 0.25925925925925924)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The Bayes estimator function which returns probability of one M&M being from\n",
    "bag94 and other being from bag96 and also the opposite scenario.\n",
    "We have created 2 events as follows\n",
    "- A being the event where Bag1 is from 1994 and Bag2 is from 1996\n",
    "- B being the event where Bag2 is from 1994 and Bag1 is from 1996\n",
    "event_A_prob : The prob of event A to occur, which is 0.5\n",
    "event_B_prob : The prob of event B to occur, which is 0.5\n",
    "drawn_from_94_then_96 : The prob of drawing first coloured M&M from bag94 and second from bag96\n",
    "drawn_from_96_then_94 : The prob of drawing second coloured M&M from bag94 and first from bag96\n",
    "'''\n",
    "def bayes_estimator(event_A_prob, event_B_prob, drawn_from_94_then_96, drawn_from_96_then_94):\n",
    "    occurance = \\\n",
    "        (event_A_prob * drawn_from_94_then_96) + \\\n",
    "        (event_B_prob * drawn_from_96_then_94)\n",
    "    # Probability hypothesis of A\n",
    "    prob_hy_A = event_A_prob * (drawn_from_94_then_96 / occurance)\n",
    "    # Probability hypothesis of B\n",
    "    prob_hy_B = event_B_prob * (drawn_from_96_then_94 / occurance)\n",
    "\n",
    "    return prob_hy_A, prob_hy_B\n",
    "\n",
    "\n",
    "prob_A = 0.5\n",
    "prob_B = 0.5\n",
    "# Probability that drawing yellow M&M from bag94 and green M&M from bag96\n",
    "prob_of_drawing_event_A = 0.2 * 0.2\n",
    "# Probability that drawing green M&M from bag94 and yellow M&M from bag96\n",
    "prob_of_drawing_event_B = 0.14 * 0.10\n",
    "\n",
    "prob_that_Y_1994 = bayes_estimator(prob_A, prob_B, prob_of_drawing_event_A, prob_of_drawing_event_B) \n",
    "print(prob_that_Y_1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Do we really need Bayes Law?\n",
    "\n",
    "An alternative approach was suggested by Peter Norvig as he reflected on Allen Downey's example...\n",
    "\n",
    "In a sense it is curious that this problem comes from a section titled by Downey as **My favorite Bayes's Theorem Problems**, as you might expect that you would need to invoke Bayes Theorem to solve it. However, the enumerative approach outlined below shows that is not strictly necessary.\n",
    "\n",
    "Yes, Bayes Theorem allows you to do less calculation but at the cost of more algebra; that is a great trade-off if you are working with pencil and paper. Enumerating the state space allows you to do less algebra at the cost of more calculation; sometimes a good trade-off if you have a computer. Using both approaches may help you to more fully understand Bayes theorem and how it works (or at least confirm that the algebra agrees with the enumerated outcome!).\n",
    "\n",
    "We can use some of the code that was introduced to us in Norvig's tutorial examples of urn problems from last week. We will start by re-introducing the various functions that he developed there, though here they are replaced with slightly 'enhanced' versions (but essentially acheive the same results).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def P(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "    \n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...};\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...};\n",
    "    in both cases only with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To tackle this particulars of this problem, we'll need to represent the probability distributions of the difference M&Ms in each bag.  We define a `ProbDist` function and then use it to create the distribution of differing colours of M&Ms contained in `bag94` and `bag96`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist(dict):\n",
    "    \"A Probability Distribution; an {outcome: probability} mapping.\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        # Make probabilities sum to 1.0; assert no negative probabilities\n",
    "        total = sum(self.values())\n",
    "        for outcome in self:\n",
    "            self[outcome] = self[outcome] / total\n",
    "            assert self[outcome] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(blue=24, green=20, orange=16, yellow=14, red=13, brown=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 0.3,\n",
       " 'yellow': 0.2,\n",
       " 'red': 0.2,\n",
       " 'green': 0.1,\n",
       " 'orange': 0.1,\n",
       " 'tan': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check the contents of a bag (or more correctly the propotions of differing colour contents in a bag)\n",
    "bag94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We can now define `two_MM` as the joint distribution - the sample space for picking two M&Ms, one from each of the bags defined by these two distributions. The outcome `'brown - blue'` means that a brown M&M was selected from the 1994 bag and that a blue one came from the 1996 bag. There will be no entry for `blue - brown` as there were no blue M&Ms in the bags from before 1995, but for many selections we are able to find the values for various `a - b` and `b - a` outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown - blue': 0.07199999999999997,\n",
       " 'brown - green': 0.05999999999999997,\n",
       " 'brown - orange': 0.04799999999999998,\n",
       " 'brown - yellow': 0.04199999999999998,\n",
       " 'brown - red': 0.038999999999999986,\n",
       " 'brown - brown': 0.038999999999999986,\n",
       " 'yellow - blue': 0.04799999999999998,\n",
       " 'yellow - green': 0.03999999999999999,\n",
       " 'yellow - orange': 0.03199999999999999,\n",
       " 'yellow - yellow': 0.02799999999999999,\n",
       " 'yellow - red': 0.025999999999999992,\n",
       " 'yellow - brown': 0.025999999999999992,\n",
       " 'red - blue': 0.04799999999999998,\n",
       " 'red - green': 0.03999999999999999,\n",
       " 'red - orange': 0.03199999999999999,\n",
       " 'red - yellow': 0.02799999999999999,\n",
       " 'red - red': 0.025999999999999992,\n",
       " 'red - brown': 0.025999999999999992,\n",
       " 'green - blue': 0.02399999999999999,\n",
       " 'green - green': 0.019999999999999993,\n",
       " 'green - orange': 0.015999999999999993,\n",
       " 'green - yellow': 0.013999999999999995,\n",
       " 'green - red': 0.012999999999999996,\n",
       " 'green - brown': 0.012999999999999996,\n",
       " 'orange - blue': 0.02399999999999999,\n",
       " 'orange - green': 0.019999999999999993,\n",
       " 'orange - orange': 0.015999999999999993,\n",
       " 'orange - yellow': 0.013999999999999995,\n",
       " 'orange - red': 0.012999999999999996,\n",
       " 'orange - brown': 0.012999999999999996,\n",
       " 'tan - blue': 0.02399999999999999,\n",
       " 'tan - green': 0.019999999999999993,\n",
       " 'tan - orange': 0.015999999999999993,\n",
       " 'tan - yellow': 0.013999999999999995,\n",
       " 'tan - red': 0.012999999999999996,\n",
       " 'tan - brown': 0.012999999999999996}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "two_MM = joint(bag94, bag96, ' - ')\n",
    "two_MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So now we can look at the possible ways in which we could end up with a \"one is yellow and one is green\" outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yellow - green': 0.7407407407407408, 'green - yellow': 0.25925925925925924}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "\n",
    "such_that(yellow_and_green, two_MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "As you can see, these two numbers must sum to 1... if we have a 'yellow and green' outcome, then either we picked them in the order of the 94/96, or order of the 96/94, bags.\n",
    "\n",
    "We therefore don't really need this last/next cell, but if we wanted to test in Python...\n",
    "\n",
    "We can answer the question: given that we got a yellow and a green (but don't know which comes from which bag), what is the probability that the yellow came from the 1994 bag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yellow94(outcome): return outcome.startswith('yellow')\n",
    "\n",
    "P(yellow94, such_that(yellow_and_green, two_MM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we end up with the same outcome as when we used Bayes' Rule in the previous section. Take some time (in the little exercise below) to reflect on these two approaches with some additional examples and provide some comments on your thoughts regarding the approach/outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercise 2b (SUBMIT)\n",
    "\n",
    "Try some alternative outcomes - say that you were given an **orange and a red M&M**.  What is the probability that the orange M&M came from the 1994 bag?  \n",
    "\n",
    "What about if you got a **tan and a red**?  What is the probabilty that the red came from the 1994 bag?\n",
    "\n",
    "You should try both the 'Bayesian' and the enumerative (Norvig's) approach.  Which did you find easier?  Which seemed more intuitive to you and why?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'red - orange': 0.711111111111111, 'orange - red': 0.2888888888888889}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orange_and_red(outcome): return 'orange' in outcome and 'red' in outcome\n",
    "\n",
    "such_that(orange_and_red, two_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2888888888888889, 0.7111111111111111)\n"
     ]
    }
   ],
   "source": [
    "prob_A = 0.5\n",
    "prob_B = 0.5\n",
    "# Probability that drawing orange M&M from bag94 and red M&M from bag96\n",
    "prob_of_drawing_event_A = 0.10 * 0.13\n",
    "# Probability that drawing red M&M from bag94 and orange M&M from bag96\n",
    "prob_of_drawing_event_B = 0.20 * 0.16\n",
    "\n",
    "prob_that_Y_1994 = bayes_estimator(prob_A, prob_B, prob_of_drawing_event_A, prob_of_drawing_event_B) \n",
    "print(prob_that_Y_1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tan - red': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tan_and_red(outcome): return 'tan' in outcome and 'red' in outcome\n",
    "\n",
    "such_that(tan_and_red, two_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "prob_A = 0.5\n",
    "prob_B = 0.5\n",
    "# Probability that drawing tan M&M from bag94 and red M&M from bag96\n",
    "prob_of_drawing_event_A = 0.10 * 0.20\n",
    "# Probability that drawing red M&M from bag94 and tan M&M from bag96\n",
    "prob_of_drawing_event_B = 0.20 * 0\n",
    "\n",
    "prob_that_Y_1994 = bayes_estimator(prob_A, prob_B, prob_of_drawing_event_A, prob_of_drawing_event_B) \n",
    "print(prob_that_Y_1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the Bayes Theorem and its working with different problems we really found that the Bayesian method while programming was very helpful.\n",
    "Although it has its own downside while naming the variables into the code (which is very tough task to be frank!).\n",
    "Then with the enumerative(Norvig's) approach we see that it can be computationally very cost effective and with larger samples.\n",
    "\n",
    "Surely the easier and more intuitive one is the Bayesian method with the proper understanding towards the Bayes Theorem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dabaf40d57ef3179b337d32c92b370fecaf8760e3cbe0090b9792ec52fc49b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
